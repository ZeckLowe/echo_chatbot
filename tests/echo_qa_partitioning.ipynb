{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import hashlib\n",
    "from pinecone import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "import ast\n",
    "from rapidfuzz import fuzz\n",
    "from datetime import datetime\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain import hub\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeck Lowe\\AppData\\Local\\Temp\\ipykernel_34708\\480772498.py:9: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  client = OpenAI(api_key=OPENAI_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "# Get API Keys\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "# Pinecone Initialization\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"echo-openai\")\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=\"transcript ni siya\",\n",
    "    index_name=input(\"Give meeting title\"),\n",
    "    embedding=\"embeddings of transcript\",\n",
    "    namespace=input(\"Give organization name\")\n",
    ")\n",
    "\n",
    "retriever = docsearch.as_retriever()\n",
    "\n",
    "# OpenAI Initialization\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "EMBEDDINGS = OpenAIEmbeddings(model='text-embedding-3-small', openai_api_key=OPENAI_API_KEY)\n",
    "LLM = ChatOpenAI(temperature=0.0, model_name=\"gpt-4-turbo\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    LLM, retrieval_qa_chat_prompt\n",
    ")\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever, combine_docs_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was the QA perspective on the kickoff meeting?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
